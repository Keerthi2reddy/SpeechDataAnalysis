{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(audio, sr, n_fft=512, hop_length=256, n_std_thresh=1.5):\n",
    "    stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)\n",
    "    magnitude, phase = np.abs(stft), np.angle(stft)\n",
    "    noise_magnitude = np.mean(magnitude[:, :10], axis=1, keepdims=True)\n",
    "    threshold = noise_magnitude * n_std_thresh\n",
    "    mask = magnitude > threshold\n",
    "    stft_clean = mask * magnitude * np.exp(1j * phase)\n",
    "    audio_clean = librosa.istft(stft_clean, hop_length=hop_length)\n",
    "    \n",
    "    return audio_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(filepath, target_rms=0.1):\n",
    "    audio, sr = librosa.load(filepath, sr=None)\n",
    "    audio = noise_reduction(audio, sr)\n",
    "    rms = (audio ** 2).mean() ** 0.5\n",
    "    scaling_factor = target_rms / rms\n",
    "    normalized_audio = audio * scaling_factor\n",
    "    sf.write(filepath, normalized_audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(file_path, segment_duration=6, sr=16000):\n",
    "    y, _ = librosa.load(file_path, sr=sr)\n",
    "    segment_length = segment_duration * sr\n",
    "    segments = [y[i:i + segment_length] for i in range(0, len(y), segment_length)]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_for_id(base_path, participant_id, keyword):\n",
    "    \n",
    "    # search_pattern = os.path.join(base_path, f\"ID_{participant_id}_PILOT/ID_{participant_id}_level2_{keyword}.wav\")\n",
    "    # matching_files = glob.glob(search_pattern)\n",
    "\n",
    "    # return matching_files\n",
    "\n",
    "    search_pattern_1 = os.path.join(base_path, f\"ID_{participant_id}_PILOT/ID_{participant_id}_level2_{keyword}.wav\")\n",
    "    search_pattern_2 = os.path.join(base_path, f\"ID_{participant_id}_PILOT/ID_{participant_id}_level2_1_{keyword}.wav\")\n",
    "    \n",
    "    # Use glob to find matching files for both patterns\n",
    "    matching_files_1 = glob.glob(search_pattern_1)\n",
    "    matching_files_2 = glob.glob(search_pattern_2)\n",
    "    \n",
    "    # If a file is found in either of the two forms, return the matching files\n",
    "    if matching_files_1:\n",
    "        return matching_files_1\n",
    "    elif matching_files_2:\n",
    "        return matching_files_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectrogram(signal, sr=16000, n_fft=512, hop_length=256):\n",
    "    spectrogram = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
    "    spectrogram_db = librosa.amplitude_to_db(np.abs(spectrogram), ref=np.max)\n",
    "    return spectrogram_db.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spectrograms(spectrograms1, spectrogram2):\n",
    "    dtw_distances = []\n",
    "    for s1 in spectrograms1:\n",
    "        distance, path = fastdtw(s1, spectrogram2, dist=euclidean)\n",
    "        dtw_distances.append(distance)\n",
    "    return dtw_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(keyword, file_paths_dict):\n",
    "    if keyword in file_paths_dict:\n",
    "        return file_paths_dict[keyword]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {\n",
    "    \"బట్ట\": (\"బట్ట\"),\n",
    "    \"పట్ట\": (\"పట్ట\"),\n",
    "    \"అట్ట\": (\"అట్ట\"),\n",
    "    \"పాడు\": (\"పాడు\"),\n",
    "    \"పాటు\": (\"పాటు\"),\n",
    "    \"పావు\": ( \"పావు\"),\n",
    "    \"తన్ను\": (\"తన్ను\"),\n",
    "    \"దన్ను\": (\"దన్ను\"),\n",
    "    \"అన్ను\": (\"అన్ను\"),\n",
    "    \"కాటు\": (\"కాటు\"),\n",
    "    \"గాటు\": ( \"గాటు\"),\n",
    "    \"ఆటు\": (\"ఆటు\"),\n",
    "    \"ఫాలు\": (\"ఫాలు\"),\n",
    "    \"వాలు\": (\"వాలు\"),\n",
    "    \"ఆలు\": (\"ఆలు\"),\n",
    "    \"హాయి\": (\"హాయి\"),\n",
    "    \"ఆయి\": (\"ఆయి\")\n",
    "}\n",
    "file_paths_dict = {\n",
    "    \"మట్ట\": [\n",
    "        \"reference/matta.wav\"\n",
    "    ],\n",
    "    \"బట్ట\": [\n",
    "        \"reference/battaa.wav\"\n",
    "    ],\n",
    "    \"పట్ట\": [\n",
    "        \"reference/pattaa.wav\"\n",
    "    ],\n",
    "    \"అట్ట\": [\n",
    "        \"reference/atta.wav\"\n",
    "    ],\n",
    "    \"పాడు\": [\n",
    "        \"reference/paadu.wav\"\n",
    "    ],\n",
    "    \"పాటు\": [\n",
    "        \"reference/paatu.wav\"\n",
    "    ],\n",
    "    \"పావు\": [\n",
    "        \"reference/paavu.wav\"\n",
    "    ],\n",
    "    \"తన్ను\": [\n",
    "        \"reference/thannu.wav\"\n",
    "    ],\n",
    "    \"దన్ను\": [\n",
    "        \"reference/dannu.wav\"\n",
    "    ],\n",
    "    \"అన్ను\": [\n",
    "        \"reference/annu.wav\"\n",
    "    ],\n",
    "    \"కాటు\": [\n",
    "        \"reference/kaatuu.wav\"\n",
    "    ],\n",
    "    \"గాటు\": [\n",
    "        \"reference/gaatuu.wav\"\n",
    "    ],\n",
    "    \"ఆటు\": [\n",
    "        \"reference/aatu.wav\"\n",
    "    ],\n",
    "    \"ఫాలు\": [\n",
    "        \"reference/faalu.wav\"\n",
    "    ],\n",
    "    \"వాలు\": [\n",
    "        \"reference/vaalu.wav\"\n",
    "    ],\n",
    "    \"ఆలు\": [\n",
    "        \"reference/aalu.wav\"\n",
    "    ],\n",
    "    \"హాయి\": [\n",
    "        \"reference/haayi.wav\"\n",
    "    ],\n",
    "    \"ఆయి\": [\n",
    "        \"reference/aayi.wav\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files for participant ID 1:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, spectrogram \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(a_spectrograms):\n\u001b[1;32m     49\u001b[0m     a_vs_b_similarities_dtw_spec \u001b[38;5;241m=\u001b[39m compare_spectrograms(ref_spectograms, spectrogram)\n\u001b[0;32m---> 50\u001b[0m     min_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma_vs_b_similarities_dtw_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     best_match \u001b[38;5;241m=\u001b[39m keywords[a_vs_b_similarities_dtw_spec\u001b[38;5;241m.\u001b[39mindex(min_distance)]\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Store the best match and distance for each segment\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "\n",
    "# Base directory where files are located\n",
    "base_directory = \"../../Speech-Data/pilot\"\n",
    "\n",
    "# List of participant IDs from 1 to 11\n",
    "participant_ids = [str(i) for i in range(1, 12)]\n",
    "participant_ids = [1,2,3,4,5,6,7,9,14,15,17]\n",
    "# List to accumulate results before creating DataFrame\n",
    "# Create an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=[\"Participant_ID\", \"Keyword\",\n",
    "                                   \"Segment_1_Best_Match\", \"Segment_1_Min_Distance\",\n",
    "                                   \"Segment_2_Best_Match\", \"Segment_2_Min_Distance\",\n",
    "                                   \"Segment_3_Best_Match\", \"Segment_3_Min_Distance\"])\n",
    "\n",
    "# List to accumulate results before creating DataFrame\n",
    "results_list = []\n",
    "\n",
    "# Iterate over each participant ID and keyword pairs\n",
    "for participant_id in participant_ids:\n",
    "    print(f\"\\nFiles for participant ID {participant_id}:\")\n",
    "    \n",
    "    # Iterate over each keyword in pairs\n",
    "    for key, keywords in pairs.items():\n",
    "        # print(f\"  Keyword: {key}\")\n",
    "        \n",
    "        # Find files for the given ID and keyword\n",
    "        files = find_files_for_id(base_directory, participant_id, key)\n",
    "        \n",
    "        if files:\n",
    "            # Assume we're working with the first file found\n",
    "            file = files[0]\n",
    "            \n",
    "            a_segments = split_audio(file)\n",
    "            a_spectrograms = [compute_spectrogram(segment) for segment in a_segments]\n",
    "            \n",
    "            ref_spectograms = []\n",
    "            for k in keywords:\n",
    "                ref_files = get_file_paths(k, file_paths_dict)\n",
    "                for ref in ref_files:\n",
    "                    # normalize_audio(ref)\n",
    "                    ref_y, _ = librosa.load(ref, sr=16000)\n",
    "                    ref_spectrogram = compute_spectrogram(ref_y)\n",
    "                    ref_spectograms.append(ref_spectrogram)\n",
    "            \n",
    "            # Initialize variables to track matches for each segment\n",
    "            segment_matches = []\n",
    "\n",
    "            # Compare spectrograms of all segments\n",
    "            for idx, spectrogram in enumerate(a_spectrograms):\n",
    "                a_vs_b_similarities_dtw_spec = compare_spectrograms(ref_spectograms, spectrogram)\n",
    "                min_distance = min(a_vs_b_similarities_dtw_spec)\n",
    "                best_match = keywords[a_vs_b_similarities_dtw_spec.index(min_distance)]\n",
    "                \n",
    "                # Store the best match and distance for each segment\n",
    "                segment_matches.append((best_match, min_distance))\n",
    "\n",
    "            # Ensure we have results for exactly 3 segments\n",
    "            while len(segment_matches) < 3:\n",
    "                segment_matches.append((\"\", float('inf')))\n",
    "                \n",
    "            # Accumulate the result in a list\n",
    "            results_list.append({\n",
    "                \"Participant_ID\": participant_id,\n",
    "                \"Keyword\": key,\n",
    "                \"Segment_1_Best_Match\": segment_matches[0][0],\n",
    "                \"Segment_1_Min_Distance\": segment_matches[0][1],\n",
    "                \"Segment_2_Best_Match\": segment_matches[1][0],\n",
    "                \"Segment_2_Min_Distance\": segment_matches[1][1],\n",
    "                \"Segment_3_Best_Match\": segment_matches[2][0],\n",
    "                \"Segment_3_Min_Distance\": segment_matches[2][1]\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            print(f\"No files found for {key}\")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file with UTF-8 encoding\n",
    "csv_file_path = \"comparison_results_SELFMatch.csv\"\n",
    "results_df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant_ID</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Segment_1_Best_Match</th>\n",
       "      <th>Segment_1_Min_Distance</th>\n",
       "      <th>Segment_2_Best_Match</th>\n",
       "      <th>Segment_2_Min_Distance</th>\n",
       "      <th>Segment_3_Best_Match</th>\n",
       "      <th>Segment_3_Min_Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>బట్ట</td>\n",
       "      <td>బట్ట</td>\n",
       "      <td>26876.508435</td>\n",
       "      <td>బట్ట</td>\n",
       "      <td>32514.006408</td>\n",
       "      <td>బట్ట</td>\n",
       "      <td>27071.609543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>పట్ట</td>\n",
       "      <td>బట్ట</td>\n",
       "      <td>26728.107306</td>\n",
       "      <td>బట్ట</td>\n",
       "      <td>25302.239170</td>\n",
       "      <td>బట్ట</td>\n",
       "      <td>20597.251352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>పాడు</td>\n",
       "      <td>పాడు</td>\n",
       "      <td>27153.322659</td>\n",
       "      <td>పాడు</td>\n",
       "      <td>30574.545974</td>\n",
       "      <td>పాడు</td>\n",
       "      <td>27009.280378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>పాటు</td>\n",
       "      <td>పాడు</td>\n",
       "      <td>26252.911984</td>\n",
       "      <td>పాడు</td>\n",
       "      <td>25117.796288</td>\n",
       "      <td>పాడు</td>\n",
       "      <td>22412.020545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>తన్ను</td>\n",
       "      <td>తన్ను</td>\n",
       "      <td>34825.561052</td>\n",
       "      <td>తన్ను</td>\n",
       "      <td>37048.458412</td>\n",
       "      <td>తన్ను</td>\n",
       "      <td>34465.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>17</td>\n",
       "      <td>దన్ను</td>\n",
       "      <td>తన్ను</td>\n",
       "      <td>34876.103476</td>\n",
       "      <td>తన్ను</td>\n",
       "      <td>24953.635262</td>\n",
       "      <td>తన్ను</td>\n",
       "      <td>24439.352421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>17</td>\n",
       "      <td>కాటు</td>\n",
       "      <td>కాటు</td>\n",
       "      <td>21779.572892</td>\n",
       "      <td>కాటు</td>\n",
       "      <td>14082.147878</td>\n",
       "      <td>కాటు</td>\n",
       "      <td>12026.393308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>17</td>\n",
       "      <td>గాటు</td>\n",
       "      <td>కాటు</td>\n",
       "      <td>29741.120228</td>\n",
       "      <td>కాటు</td>\n",
       "      <td>21244.118831</td>\n",
       "      <td>కాటు</td>\n",
       "      <td>15508.218428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>17</td>\n",
       "      <td>ఫాలు</td>\n",
       "      <td>ఫాలు</td>\n",
       "      <td>39346.098911</td>\n",
       "      <td>వాలు</td>\n",
       "      <td>26643.289359</td>\n",
       "      <td>ఫాలు</td>\n",
       "      <td>24902.718965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>17</td>\n",
       "      <td>వాలు</td>\n",
       "      <td>వాలు</td>\n",
       "      <td>31221.513474</td>\n",
       "      <td>వాలు</td>\n",
       "      <td>25302.724819</td>\n",
       "      <td>ఫాలు</td>\n",
       "      <td>25075.288145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Participant_ID Keyword Segment_1_Best_Match  Segment_1_Min_Distance  \\\n",
       "0                1    బట్ట                 బట్ట            26876.508435   \n",
       "1                1    పట్ట                 బట్ట            26728.107306   \n",
       "2                1    పాడు                 పాడు            27153.322659   \n",
       "3                1    పాటు                 పాడు            26252.911984   \n",
       "4                1   తన్ను                తన్ను            34825.561052   \n",
       "..             ...     ...                  ...                     ...   \n",
       "89              17   దన్ను                తన్ను            34876.103476   \n",
       "90              17    కాటు                 కాటు            21779.572892   \n",
       "91              17    గాటు                 కాటు            29741.120228   \n",
       "92              17    ఫాలు                 ఫాలు            39346.098911   \n",
       "93              17    వాలు                 వాలు            31221.513474   \n",
       "\n",
       "   Segment_2_Best_Match  Segment_2_Min_Distance Segment_3_Best_Match  \\\n",
       "0                  బట్ట            32514.006408                 బట్ట   \n",
       "1                  బట్ట            25302.239170                 బట్ట   \n",
       "2                  పాడు            30574.545974                 పాడు   \n",
       "3                  పాడు            25117.796288                 పాడు   \n",
       "4                 తన్ను            37048.458412                తన్ను   \n",
       "..                  ...                     ...                  ...   \n",
       "89                తన్ను            24953.635262                తన్ను   \n",
       "90                 కాటు            14082.147878                 కాటు   \n",
       "91                 కాటు            21244.118831                 కాటు   \n",
       "92                 వాలు            26643.289359                 ఫాలు   \n",
       "93                 వాలు            25302.724819                 ఫాలు   \n",
       "\n",
       "    Segment_3_Min_Distance  \n",
       "0             27071.609543  \n",
       "1             20597.251352  \n",
       "2             27009.280378  \n",
       "3             22412.020545  \n",
       "4             34465.000439  \n",
       "..                     ...  \n",
       "89            24439.352421  \n",
       "90            12026.393308  \n",
       "91            15508.218428  \n",
       "92            24902.718965  \n",
       "93            25075.288145  \n",
       "\n",
       "[94 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nComparison Results:\")\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechenv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
