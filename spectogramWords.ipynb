{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import nbformat as nbf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing the audio files\n",
    "base_dir = \"../../Speech-Data/pilot\"  # Update this to the correct path\n",
    "\n",
    "# List of words\n",
    "# words  = ['హరితం', 'మనస్సు', 'పోరాటం', 'ఫలితము', 'పరిషత్', 'తరువాత', 'ఎగుమతి', 'పట్ట', 'బట్ట', 'తన్ను', 'వామి', 'ఫాలు', 'కసాయి', 'ఆవు', 'వాని', 'కల', 'పాటు', 'పాడు', 'రాలు', 'కాశి', 'కాటు', 'గాటు', 'హాయి', 'బేణ్డు', 'అను', 'పిల్లి', 'మెట్టు']\n",
    "# word_english = ['haritham','manassu','poraatam','phalitamu','parishath','taruvath','egumathi','patta','batta','thannu','vaami','faalu','kasaayi','aavu','vaani','kala','paatu','paadu','raalu','kaashi','kaatu','gaatu','haayi','baendu','anu','pilli','mettu']\n",
    "\n",
    "words  = [\"బట్ట\", \"పట్ట\", \"అట్ట\", \"పాడు\", \"పాటు\", \"పావు\", \"తన్ను\", \"దన్ను\", \"అన్ను\", \"కాటు\", \"గాటు\", \"ఆటు\", \"ఫాలు\", \"వాలు\", \"ఆలు\", \"హాయి\", \"ఆయి\"]\n",
    "word_english  = [ \"batta\", \"patta\", \n",
    "    \"atta\", \"paadu\", \"paatu\", \"paavu\", \n",
    "    \"thannu\", \"dannu\", \"annu\", \n",
    "    \"kaatu\", \"gaatu\", \"aatu\", \n",
    "    \"faalu\", \"vaalu\", \"aalu\", \n",
    "    \"haayi\", \"aayi\"]\n",
    "# Function to find audio files\n",
    "def find_audio_files(base_dir, words):\n",
    "    audio_files = {word: [] for word in words}\n",
    "    for folder in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Extract the ID number from the folder name\n",
    "            folder_id = folder.split('_')[1]\n",
    "            # print(f'Processing folder {folder_id}')\n",
    "            for word in words:\n",
    "                word_clean = word.strip('/')\n",
    "                pattern1 = os.path.join(folder_path, f'ID_{folder_id}_level2_{word_clean}.wav')\n",
    "                files1 = glob.glob(pattern1)\n",
    "                pattern2 = os.path.join(folder_path, f'ID_{folder_id}_level2_1_{word_clean}.wav')\n",
    "                files2 = glob.glob(pattern2)\n",
    "                if files1:\n",
    "                    audio_files[word].append((folder_id, files1[0]))\n",
    "                elif files2:\n",
    "                    audio_files[word].append((folder_id, files2[0]))\n",
    "                    # print(f'Found {len(files)} files for word {word}')\n",
    "    return audio_files\n",
    "\n",
    "audio_files = find_audio_files(base_dir, words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = {word: [] for word in words}\n",
    "for word in words:\n",
    "    for id,file in audio_files[word]:\n",
    "        data, sr = librosa.load(file)\n",
    "        \n",
    "        audio_data[word].append({\n",
    "            'id': id,\n",
    "            'data': data,\n",
    "        })\n",
    "        # audio_data[word].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data_truncated = {word: [] for word in words}\n",
    "for word in words:\n",
    "    # for data in audio_data[word]:\n",
    "    for entry in audio_data[word]:\n",
    "        file_id = entry['id']  # Extracting the ID from the entry\n",
    "        data = entry['data'] \n",
    "        total_length = len(data)\n",
    "        part_length = total_length // 3\n",
    "\n",
    "        # Split the audio into three equal parts\n",
    "        parts = [data[:part_length], data[part_length:2*part_length], data[2*part_length:]]\n",
    "        trimmed_parts = []\n",
    "\n",
    "        # Trim each part and save the trimmed versions into trimmed_parts array\n",
    "        for part in parts:\n",
    "            trimmed_part, _ = librosa.effects.trim(part, top_db=35)\n",
    "            trimmed_parts.append(trimmed_part)\n",
    "\n",
    "        audio_data_truncated[word].append((file_id,trimmed_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the directory if it does not exist\n",
    "output_dir = 'SpectrogramPlotsWords_new_list'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Prepare data for plotting\n",
    "data_truncated_by_word = {word: [] for word in words}\n",
    "for word in words:\n",
    "    data_truncated_by_word[word] = audio_data_truncated[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create plots for each word\n",
    "for word, data_truncated in data_truncated_by_word.items():\n",
    "    num_plots = len(data_truncated) * 3  # Each word has 3 parts for each segment\n",
    "    num_cols = 3  # Number of columns per row (3 parts)\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "    # Create a figure and axis objects for the current word\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
    "    \n",
    "    # Flatten the axes array for easy indexing\n",
    "    axs = axs.flatten() if num_rows > 1 else [axs]\n",
    "    \n",
    "    # Iterate through each segment and plot in a subplot\n",
    "    plot_index = 0\n",
    "    for id,segment in data_truncated:\n",
    "           \n",
    "        for part in segment:\n",
    "            # Compute STFT\n",
    "            transformed_part = librosa.stft(part)\n",
    "            \n",
    "            # Convert to dB\n",
    "            db = librosa.amplitude_to_db(np.abs(transformed_part))\n",
    "            \n",
    "            # Plot spectrogram\n",
    "            # axs[plot_index].imshow(db, aspect='auto', origin='lower', cmap='inferno')\n",
    "            # axs[plot_index].set_title(f'Part {plot_index % 3 + 1}')\n",
    "            # axs[plot_index].set_xlabel('Time')\n",
    "            # axs[plot_index].set_ylabel('Frequency')\n",
    "            # axs[plot_index].set_ylim(0, 400)\n",
    "\n",
    "            ax_spectrogram = axs[plot_index]\n",
    "            ax_spectrogram.imshow(db, aspect='auto', origin='lower', cmap='inferno')\n",
    "            ax_spectrogram.set_title(f'Spectrogram Part {plot_index % 3 + 1} of {id}')\n",
    "            ax_spectrogram.set_xlabel('Time')\n",
    "            ax_spectrogram.set_ylabel('Frequency')\n",
    "            # ax_spectrogram.set_ylim(0, 400)\n",
    "            \n",
    "            plot_index += 1\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(plot_index, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    # Adjust layout and add a title for the word\n",
    "    word_index = words.index(word)\n",
    "    plt.suptitle(f'Spectrograms for word: {word_english[word_index]}', fontsize=16)\n",
    "    # plt.suptitle(f'Spectrograms for word: {word}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    # Save the plot as an image file\n",
    "    plot_file_path = os.path.join(output_dir, f'{word}.png')\n",
    "    plt.savefig(plot_file_path)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for each word\n",
    "for word, data_truncated in data_truncated_by_word.items():\n",
    "    num_plots = len(data_truncated) * 3  # Each word has 3 parts for each segment\n",
    "    num_cols = 3  # Number of columns per row (3 parts)\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "    \n",
    "    # Create a figure and axis objects for the current word\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
    "    \n",
    "    # Flatten the axes array for easy indexing\n",
    "    axs = axs.flatten() if num_rows > 1 else [axs]\n",
    "    \n",
    "    # Iterate through each segment and plot in a subplot\n",
    "    plot_index = 0\n",
    "    for id,segment in data_truncated:\n",
    "        for part in segment:\n",
    "            ax_waveform = axs[plot_index]\n",
    "            ax_waveform.plot(part, lw=1)\n",
    "            ax_waveform.set_title(f'Waveform Part {plot_index % 3 + 1} of {id}')\n",
    "            ax_waveform.set_xlabel('Time')\n",
    "            ax_waveform.set_ylabel('Amplitude')\n",
    "            \n",
    "            plot_index += 1\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(plot_index, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    # Adjust layout and add a title for the word\n",
    "    \n",
    "    word_index = words.index(word)\n",
    "    plt.suptitle(f'WaveForms for word: {word_english[word_index]}', fontsize=16)\n",
    "    # plt.suptitle(f'Spectrograms for word: {word}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    # Save the plot as an image file\n",
    "    plot_file_path = os.path.join(output_dir, f'{word}_wave.png')\n",
    "    plt.savefig(plot_file_path)\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechenv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
